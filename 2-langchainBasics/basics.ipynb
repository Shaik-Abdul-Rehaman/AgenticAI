{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e5b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bffbe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\", \"your_langchain_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\", \"your_langchain_project_here\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\", \"your_groq_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.getenv(\"GROQ_API_KEY\", \"your_groq_api_key_here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b04a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, the user wants a joke about cats. Let me think of some common cat-related themes. Cats love laser pointers, right? Maybe I can play on that. Why don\\'t cats like laser pointers? Because they\\'re always running away from the dot... Wait, maybe that\\'s not the best punchline.\\n\\nHmm, how about something with a pun or a play on words. Cats and mice? Like the classic cat and mouse scenario. Oh, right! Why did the cat sit on the computer? To keep an eye on the mouse! That\\'s a classic one. Wait, but maybe I can make it even better. Let me check if that\\'s a common joke or if it\\'s too overused. I think it\\'s a standard pun, but it\\'s funny and straightforward. Alternatively, maybe something about their nine lives. But nine lives jokes can be a bit clich√©. Let\\'s see... Maybe the first idea works better. Yeah, the mouse on the computer is a good pun. Okay, let\\'s go with that. Alternatively, maybe something else. What else do cats do? They meow, they purr, they have whiskers, they like milk... Wait, another angle: Why don\\'t cats like online shopping? They prefer a cat-alog. Hmm, that\\'s okay but maybe not as strong. Let me think again. The computer and mouse joke is solid. Alright, I\\'ll use that one. Let me check if the wording is right. \"Why did the cat sit on the computer? To keep an eye on the mouse!\" Yeah, that should work. It\\'s simple and punny. Alright, that\\'s the one.\\n</think>\\n\\nSure! Here\\'s a feline-friendly joke for you:\\n\\n**Why did the cat sit on the computer?**  \\n*To keep an eye on the mouse!* üê±üñ±Ô∏è' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 380, 'prompt_tokens': 16, 'total_tokens': 396, 'completion_time': 0.946469739, 'prompt_time': 0.003264268, 'queue_time': 0.245167931, 'total_time': 0.949734007}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None} id='run--9e423c53-45b6-4888-878a-8412fb924768-0' usage_metadata={'input_tokens': 16, 'output_tokens': 380, 'total_tokens': 396}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result=model.invoke(\"tell me a joke about cats\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4dbe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user wants a joke about cats. Let me think of some common cat-related humor. Maybe something with a play on words. Cats love laser pointers, but they can\\'t catch them. That\\'s a classic. How about a pun involving \"purr\" and \"pur-r-l? Wait, maybe a light-hearted scenario where the cat is confused by the laser. Let me structure it as a question and answer. \"Why don‚Äôt cats ever get tired of chasing laser dots?\" Then the punchline: \"Because they‚Äôre light workers!\" Wait, \"light workers\" sounds like \"night workers,\" but maybe that\\'s not the best. Hmm, maybe \"Because they‚Äôre drawn to the laser‚Äôs‚Ä¶ ‚Äòpurr‚Äô-spective!\" No, that\\'s a bit forced. Alternatively, \"Because it‚Äôs their laser focus!\" Not quite. Wait, the original idea was \"light workers\" as a play on \"night workers.\" Maybe that\\'s okay. Let me check again. The setup is about why cats keep chasing the laser, and the punchline is that they\\'re \"light workers,\" implying they work with light (the laser) but also a pun on \"night workers\" who work at night. That\\'s a solid pun. Let me make sure it\\'s clear. Yeah, I think that works. Alright, that should be the joke.\\n</think>\\n\\nSure! Here\\'s a feline-friendly joke for you:\\n\\n**Why don‚Äôt cats ever get tired of chasing laser dots?**  \\n*Because they‚Äôre light workers!* üêæ‚ú®  \\n\\n(Get it? Light *workers* vs. night *shift*? Okay, I‚Äôll cat-tastrophize if you don‚Äôt laugh‚Ä¶ üò∫)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "chain=model| parser\n",
    "chain.invoke(\"tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829e428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758c443e",
   "metadata": {},
   "source": [
    "### chaining with some extra stuff using promptTemplate and ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert language translator.\"),\n",
    "    (\"human\", \"Your task is to convert the following text into '{language}' language:\\n\\n'{text}'\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9c470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert language translator.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, template=\"Your task is to convert the following text into '{language}' language:\\n\\n'{text}'\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format_messages(\n",
    "    language=\"hindi\",\n",
    "    text=\"my name is rehaman , i want to learn agentic AI\"\n",
    "    \n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfaf4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, the user wants me to translate \"my name is rehaman, I want to learn agentic AI\" into Hindi. Let me break this down.\\n\\nFirst, \"my name is\" translates to \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à\". That\\'s straightforward.\\n\\nNext, \"rehaman\" is a name, so it\\'ll stay as is but in Hindi script. Maybe write it as \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" to match the pronunciation. \\n\\nThen, \"I want to learn\" ‚Äì the verb here is \"want\", which is \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" for a male speaker. Since the name Rehaman is typically a male name, I\\'ll use the masculine form. \\n\\n\"Learn\" is \"‡§∏‡•Ä‡§ñ‡§®‡§æ\", so \"want to learn\" becomes \"‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \\n\\nNow the last part: \"agentic AI\". \"Agentic\" might be a less common term. In Hindi, \"agentic\" could be translated as \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï\" since it\\'s a technical term. \"AI\" is commonly written as \"‡§Ü‡§à\" but sometimes spelled out as \"‡§ï‡•â‡§™‡•ç‡§Ø‡•Å‡§∞‡•á‡§ü ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§∏\" but in this context, \"‡§Ü‡§à\" should suffice. Alternatively, \"‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à\" but maybe \"‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à\" is better. Wait, maybe \"‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à\" is the right way to put it. \\n\\nPutting it all together: \\n\\n\"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à ‡§∞‡•á‡§π‡§Æ‡§æ‡§®, ‡§Æ‡•à‡§Ç ‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"\\n\\nWait, let me check the structure again. The original is \"I want to learn agentic AI\". The Hindi structure should have the verb after the object? Or does it follow the same structure? In Hindi, typically, the structure is subject - verb, so \"‡§Æ‡•à‡§Ç ‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" should be correct. \\n\\nAlternatively, \"‡§Æ‡•Å‡§ù‡•á ‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§π‡•à\" could also mean \"I want to learn\", but \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" is more explicit. \\n\\nAlso, need to confirm the spelling of \"agentic\" in Hindi. Since it\\'s a technical term, it\\'s better to keep it in English transliteration. \"Agent\" is \"‡§è‡§ú‡•á‡§Ç‡§ü\", so \"agentic\" might be \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï\". \\n\\nSo the final translation should be: \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à ‡§∞‡•á‡§π‡§Æ‡§æ‡§®, ‡§Æ‡•à‡§Ç ‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \\n\\nWait, the user wrote \"agentic AI\" ‚Äì maybe it\\'s \"agentic\" as in \"agent-based\" or \"agent\" AI? Maybe \"‡§ê‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§à\" but the user wrote \"agentic\", so better stick with the transliteration. \\n\\nI think that\\'s it. Double-check for any errors in grammar or structure. Looks good.\\n</think>\\n\\n‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à ‡§∞‡•á‡§π‡§Æ‡§æ‡§®, ‡§Æ‡•à‡§Ç ‡§ê‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å‡•§' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 800, 'prompt_tokens': 53, 'total_tokens': 853, 'completion_time': 1.950321295, 'prompt_time': 0.00558053, 'queue_time': 0.247825559, 'total_time': 1.955901825}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None} id='run--53780f30-b897-470c-a16f-4650576955c3-0' usage_metadata={'input_tokens': 53, 'output_tokens': 800, 'total_tokens': 853}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f608aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user wants me to translate \"hii how are you\" into German. Let me start by analyzing the original text. \"Hii\" is a casual, informal way of saying \"hi,\" maybe with an extra \\'i\\' for emphasis or friendliness. \"How are you\" is the standard greeting question.\\n\\nFirst, I need to translate each part accurately while maintaining the informal tone. \"Hii\" in German could be \"Hi\" or \"Hey,\" but since it\\'s doubled, maybe \"Hihi\" to match the style, though that\\'s a bit unconventional. Alternatively, just \"Hi\" might be better to keep it natural. Then \"how are you\" translates to \"wie geht\\'s\" which is the informal way. The full form is \"Wie geht es dir?\" but the shortened version is more common in casual talk.\\n\\nPutting it together: \"Hi, wie geht\\'s?\" That sounds right. I should check if \"Hihi\" is necessary. The user might be aiming for a playful \"hii,\" but in German, \"Hi\" alone is sufficient. Also, ensuring the punctuation is correct with a comma. Maybe the user wants the greeting to be friendly but not overly so. So the best translation is \"Hi, wie geht\\'s?\" \\n\\nWait, is there a more common phrase? Sometimes people use \"Was geht?\" but that\\'s more like \"What\\'s up?\" So sticking with \"wie geht\\'s\" is safer for a direct translation. I think that\\'s it. Let me confirm with a quick check. Yep, that should be correct.\\n</think>\\n\\n\\'Hallo, wie geht es dir?\\''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt|model|parser\n",
    "response=chain.invoke({\n",
    "    \"language\":\"german\",\n",
    "    \"text\":\"hii how are you\"\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "746cbd15",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: <think>\nOkay, the user wants me to translate \"my name is rehaman, I want to learn agentic AI\" into Hindi. Let me start by breaking down the sentence. \n\nFirst part: \"my name is rehaman\" ‚Äì in Hindi, that would be \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à\". I need to make sure the name \"rehaman\" is spelled correctly in Hindi. Since it's a name, it's usually transliterated. So \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" should be right.\n\nNext part: \"I want to learn agentic AI\". The verb \"want\" is \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" for a male speaker. Assuming the user is male since the name Rehaman is typically male. If not specified, but better to go with the common usage.\n\n\"to learn\" is \"‡§∏‡•Ä‡§ñ‡§®‡§æ\". Then \"agentic AI\" ‚Äì \"agentic\" here probably refers to \"agent-based\" or \"agentic\" as in having agency. In Hindi tech contexts, sometimes terms are kept in English, but maybe translate it. \"Agentic\" could be \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï\" since it's a technical term. \"AI\" is commonly \"AI\" in Hindi too, but can also write \"‡§™‡§∞‡§Æ‡§æ‡§£‡•Å ‡§¨‡•à‡§®‡•ç‡§°\" no, wait, AI is \"Artificial Intelligence\" which is \"‡§ïificial Intelligence\" in Hindi, but people just say \"AI\". So \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\" or maybe \"‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§à\" but the user wrote \"agentic AI\" so probably keep it as \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\". \n\nPutting it all together: \"‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \n\nWait, the structure in Hindi would be \"I want to learn agentic AI\" ‚Üí \"‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". That seems correct. Let me check the order. \"‡§Æ‡•à‡§Ç [infinitive verb] ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" so \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" comes at the end. \n\nSo combining both parts: \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \n\nWait, the user wrote \"rehaman\" ‚Äì should it be \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" or \"‡§∞‡§π‡§Æ‡§æ‡§®\"? Since they wrote 'rehaman', the 'e' might be making it \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\". But sometimes \"rehman\" could be \"‡§∞‡§π‡§Æ‡§æ‡§®\", but I'll go with the user's spelling as given. \n\nAlso, check if \"agentic\" is the correct term here. Maybe the user means \"agent-based\" AI, but since they specified \"agentic\", I'll stick to that. \n\nDouble-checking the sentence structure. Yes, the translation seems accurate. So the final JSON should be {\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}.\n</think>\n\n{\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:88\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m chain = prompt | model | parser\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Step 6: Invoke the chain\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlanguage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhindi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy name is rehaman, I want to learn agentic AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:91\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     90\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: <think>\nOkay, the user wants me to translate \"my name is rehaman, I want to learn agentic AI\" into Hindi. Let me start by breaking down the sentence. \n\nFirst part: \"my name is rehaman\" ‚Äì in Hindi, that would be \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à\". I need to make sure the name \"rehaman\" is spelled correctly in Hindi. Since it's a name, it's usually transliterated. So \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" should be right.\n\nNext part: \"I want to learn agentic AI\". The verb \"want\" is \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" for a male speaker. Assuming the user is male since the name Rehaman is typically male. If not specified, but better to go with the common usage.\n\n\"to learn\" is \"‡§∏‡•Ä‡§ñ‡§®‡§æ\". Then \"agentic AI\" ‚Äì \"agentic\" here probably refers to \"agent-based\" or \"agentic\" as in having agency. In Hindi tech contexts, sometimes terms are kept in English, but maybe translate it. \"Agentic\" could be \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï\" since it's a technical term. \"AI\" is commonly \"AI\" in Hindi too, but can also write \"‡§™‡§∞‡§Æ‡§æ‡§£‡•Å ‡§¨‡•à‡§®‡•ç‡§°\" no, wait, AI is \"Artificial Intelligence\" which is \"‡§ïificial Intelligence\" in Hindi, but people just say \"AI\". So \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\" or maybe \"‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§à\" but the user wrote \"agentic AI\" so probably keep it as \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\". \n\nPutting it all together: \"‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \n\nWait, the structure in Hindi would be \"I want to learn agentic AI\" ‚Üí \"‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". That seems correct. Let me check the order. \"‡§Æ‡•à‡§Ç [infinitive verb] ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" so \"‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" comes at the end. \n\nSo combining both parts: \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \n\nWait, the user wrote \"rehaman\" ‚Äì should it be \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" or \"‡§∞‡§π‡§Æ‡§æ‡§®\"? Since they wrote 'rehaman', the 'e' might be making it \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\". But sometimes \"rehman\" could be \"‡§∞‡§π‡§Æ‡§æ‡§®\", but I'll go with the user's spelling as given. \n\nAlso, check if \"agentic\" is the correct term here. Maybe the user means \"agent-based\" AI, but since they specified \"agentic\", I'll stick to that. \n\nDouble-checking the sentence structure. Yes, the translation seems accurate. So the final JSON should be {\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}.\n</think>\n\n{\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Step 1: Define the JSON parser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an expert translator. Return ONLY this exact JSON format: {{\\\"translation\\\": \\\"...\\\"}}. No explanations, no markdown, no extra text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"Translate the following text into '{language}' language:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# Step 3: Inject format instructions from the parser\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# Step 4: Define the model\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "\n",
    "# Step 5: Create the chain\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Step 6: Invoke the chain\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe698f4",
   "metadata": {},
   "source": [
    "### JsonOutputParser without pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': '‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§è‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "parser = JsonOutputParser()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an expert translator. Return ONLY this exact JSON format: {{\\\"translation\\\": \\\"...\\\"}}. No explanations, no markdown, no extra text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"Translate the following text into '{language}' language:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "model = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6e2e1",
   "metadata": {},
   "source": [
    "### JsonOutputParser with Pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604c04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two-tired.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "joke_query = \"Tell me a joke.\"\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "chain = prompt | model | parser\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88004172",
   "metadata": {},
   "source": [
    "### JsonOutputParser without pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36b3f037",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: <think>\nOkay, the user asked for a joke. Let me think of a good one. Maybe something light and not offensive. How about a classic setup and punchline?\n\nHmm, what's a common scenario that can have a funny twist? Maybe animals? Dogs are relatable. Why did the scarecrow win an award? Because he was outstanding in his field! Wait, that's a classic but maybe overused. Let me think of another.\n\nOh, maybe a dog with a computer? Like, why don't dogs make good wrestlers? Because they have paws but not enough grip... No, not sure. Wait, the user example used a dog with a keyboard. Maybe something like that.\n\nWait, the example response was: \"Why did the scarecrow win an award? Because he was outstanding in his field!\" But maybe I should come up with a different one to avoid repetition. Let's see.\n\nAlternatively: What do you call fake spaghetti? An impasta. Hmm, maybe that's good. Or a computer-related joke. Why did the computer go to the doctor? Because it had a virus! But maybe too simple.\n\nAlternatively, maybe something with wordplay. Let's see. Okay, the user's example used the scarecrow joke. Maybe I'll go with the computer one. Or maybe a cat joke? Wait, the user wants a JSON object with the joke. Let me ensure it's original but still funny.\n\nWait, the user's example answer was the scarecrow. Let me think again. How about: Why did the bicycle fall over? Because it didn't have any legs! That's simple but maybe too obvious.\n\nAlternatively, let's try: Why can't a bicycle stand up by itself? It's a bike! Wait, that's the same idea. Maybe the first one is better. Alternatively, a joke about a calendar. Why can't a calendar control the weather? Because it just flips through the months. Hmm, not great.\n\nHmm, maybe the dog with a keyboard. \"I told my computer I needed a break, and it pressed Alt+F4!\" That's a bit techy but funny. Or the classic: What do you call a fake noodle? An impasta. Yeah, that's good.\n\nAlternatively, \"Why don't skeletons fight each other? They don't have the guts!\" Maybe a bit dark. Better stick to something lighthearted. Let's go with the impasta one. Or maybe the computer joke. Let me pick one and structure it in the JSON as per the example.\n</think>\n\n{\n  \"joke\": \"Why don‚Äôt scientists trust atoms? Because they make up everything!\"\n}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:88\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m prompt = PromptTemplate(\n\u001b[32m      6\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33mAnswer the user query.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{format_instructions}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      8\u001b[39m     partial_variables={\u001b[33m\"\u001b[39m\u001b[33mformat_instructions\u001b[39m\u001b[33m\"\u001b[39m: parser.get_format_instructions()},\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m chain = prompt | model | parser\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoke_query\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:91\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     90\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: <think>\nOkay, the user asked for a joke. Let me think of a good one. Maybe something light and not offensive. How about a classic setup and punchline?\n\nHmm, what's a common scenario that can have a funny twist? Maybe animals? Dogs are relatable. Why did the scarecrow win an award? Because he was outstanding in his field! Wait, that's a classic but maybe overused. Let me think of another.\n\nOh, maybe a dog with a computer? Like, why don't dogs make good wrestlers? Because they have paws but not enough grip... No, not sure. Wait, the user example used a dog with a keyboard. Maybe something like that.\n\nWait, the example response was: \"Why did the scarecrow win an award? Because he was outstanding in his field!\" But maybe I should come up with a different one to avoid repetition. Let's see.\n\nAlternatively: What do you call fake spaghetti? An impasta. Hmm, maybe that's good. Or a computer-related joke. Why did the computer go to the doctor? Because it had a virus! But maybe too simple.\n\nAlternatively, maybe something with wordplay. Let's see. Okay, the user's example used the scarecrow joke. Maybe I'll go with the computer one. Or maybe a cat joke? Wait, the user wants a JSON object with the joke. Let me ensure it's original but still funny.\n\nWait, the user's example answer was the scarecrow. Let me think again. How about: Why did the bicycle fall over? Because it didn't have any legs! That's simple but maybe too obvious.\n\nAlternatively, let's try: Why can't a bicycle stand up by itself? It's a bike! Wait, that's the same idea. Maybe the first one is better. Alternatively, a joke about a calendar. Why can't a calendar control the weather? Because it just flips through the months. Hmm, not great.\n\nHmm, maybe the dog with a keyboard. \"I told my computer I needed a break, and it pressed Alt+F4!\" That's a bit techy but funny. Or the classic: What do you call a fake noodle? An impasta. Yeah, that's good.\n\nAlternatively, \"Why don't skeletons fight each other? They don't have the guts!\" Maybe a bit dark. Better stick to something lighthearted. Let's go with the impasta one. Or maybe the computer joke. Let me pick one and structure it in the JSON as per the example.\n</think>\n\n{\n  \"joke\": \"Why don‚Äôt scientists trust atoms? Because they make up everything!\"\n}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41d1acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, the user wants a joke about cats. Let me think of some common cat-related humor. Cats are playful, so maybe something with their antics. Puns are always a good approach. Maybe involving cat parts or common phrases.\\n\\nHmm, \"Why don\\'t cats play poker in the jungle?\" Because there are too many cheetahs! Wait, cheetahs sound like \"cheaters.\" That\\'s a classic pun. Let me check if that works. Cheetahs vs. cheaters. Yeah, that\\'s a solid pun. It\\'s simple and cat-related. I should make sure there\\'s no confusion. Maybe some might not get it, but it\\'s a common joke structure. Alright, that\\'s a good one. Let me present it clearly.\\n</think>\\n\\nSure! Here\\'s a feline-friendly joke for you:\\n\\nWhy don‚Äôt cats play poker in the jungle?  \\n‚Ä¶Because there are too many *cheetahs*! üêÜüòÑ\\n\\n*(Get it? Cheetahs sound like \"cheaters\"‚Ä¶ and cats can be pretty judgmental about bad puns.)*' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 229, 'prompt_tokens': 16, 'total_tokens': 245, 'completion_time': 0.570070911, 'prompt_time': 0.003823884, 'queue_time': 5.394246507, 'total_time': 0.573894795}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'stop', 'logprobs': None} id='run--2e2e9274-fd05-426c-a5bb-b33181e4e0ee-0' usage_metadata={'input_tokens': 16, 'output_tokens': 229, 'total_tokens': 245}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result=model.invoke(\"tell me a joke about cats\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a4dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
