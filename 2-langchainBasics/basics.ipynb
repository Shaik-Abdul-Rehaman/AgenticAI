{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e5b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bffbe0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\", \"your_openai_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\", \"your_langchain_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\", \"your_langchain_project_here\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\", \"your_groq_api_key_here\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.getenv(\"GROQ_API_KEY\", \"your_groq_api_key_here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b04a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, the user wants a joke about cats. Let me think of some common cat-related humor. Cats are known for their quirky behaviors, like knocking things off tables, napping in sunny spots, and being a bit aloof. Maybe something with a play on words?\\n\\nHmm, \"Why did the cat sit on the computer?\" Oh, right, \"To keep an eye on the mouse!\" That\\'s a classic one. The mouse on the computer refers to the cursor or the actual mouse. It\\'s a pun that works because cats chase mice. Let me make sure it\\'s not too overused. I think it\\'s a solid choice. Alternatively, maybe another angle? Like \"Why don\\'t cats play poker in the Wild West?\" \"Too many outlaws!\" But that\\'s more about the wild west. The first one is better. I\\'ll go with the computer and mouse joke. It\\'s simple, clean, and directly relates to cats and their instincts. Yep, that should work.\\n</think>\\n\\nSure! Here\\'s a light-hearted one:  \\n\\n**Why did the cat sit on the computer?**  \\n*Because it wanted to keep an eye on the mouse!* üê±üñ±Ô∏è' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 243, 'prompt_tokens': 16, 'total_tokens': 259, 'completion_time': 0.564038918, 'prompt_time': 0.00464803, 'queue_time': 1.073552786, 'total_time': 0.568686948}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None} id='run--8d9c5e43-112c-4511-a42e-a67da7c48dfe-0' usage_metadata={'input_tokens': 16, 'output_tokens': 243, 'total_tokens': 259}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "result=model.invoke(\"tell me a joke about cats\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4dbe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user wants a joke about cats. Let me think of some common cat-related humor. Cats are known for their independent nature, their love of sitting in boxes, and their occasional mischievousness.\\n\\nMaybe I can play on the idea that cats always land on their feet. Like a pun with \"purr-son\" instead of \"person.\" Let me see... \\n\\nWait, another angle: why did the cat sit on the computer? Because it wanted to keep an eye on the mouse! But \"mouse\" here refers to the computer mouse, which is a classic pun. That\\'s good. It\\'s simple and relatable. \\n\\nAlternatively, there\\'s the one about the cat with no tail. \"What do you call a cat with no tail? A sit-ter.\" Hmm, that\\'s okay but maybe not as strong. \\n\\nThe first one with the computer mouse is better. It\\'s a common scenario, and the pun is clear. Let me make sure it\\'s not too overused. I think it\\'s a solid choice. Let me go with that one. \\n\\nWait, another thought: How do cats dance? They waltz. Because \"waltz\" sounds like \"walks\" but that\\'s more of a play on words. Maybe not as funny. \\n\\nNo, the computer mouse joke is better. Let\\'s go with that. Just to make sure, I\\'ll check if there\\'s any other puns. Maybe \"cat scan\" for a medical scan? But that\\'s more of a groaner. \\n\\nAlright, the computer mouse one is the best bet. It\\'s straightforward and ties in the cat\\'s behavior with a common object. Let\\'s present that one.\\n</think>\\n\\nWhy did the cat sit on the computer?  \\nBecause it wanted to keep an eye on the *mouse*!  \\n\\n(Meow-tastically punny, right?) üò∫'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "chain=model| parser\n",
    "chain.invoke(\"tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829e428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758c443e",
   "metadata": {},
   "source": [
    "### chaining with some extra stuff using promptTemplate and ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "240a65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert language translator.\"),\n",
    "    (\"human\", \"Your task is to convert the following text into '{language}' language:\\n\\n'{text}'\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9c470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert language translator.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, template=\"Your task is to convert the following text into '{language}' language:\\n\\n'{text}'\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format_messages(\n",
    "    language=\"hindi\",\n",
    "    text=\"my name is rehaman , i want to learn agentic AI\"\n",
    "    \n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcfaf4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, I need to translate the user\\'s message into Hindi. The original text is: \"my name is rehaman, I want to learn agentic AI\". Let me break this down.\\n\\nFirst, \"my name is\" translates to \"‡§Æ‡•à‡§Ç ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à\" in Hindi. \\n\\n\"Rehaman\" is a name, so it should remain the same, but in Hindi script it might be written as \"‡§∞‡•á‡§π‡§Æ‡§æ‡§®\" to match the phonetics. \\n\\nThen, \"I want to learn\" would be \"‡§Æ‡•à‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" (assuming the person is male; if gender is unknown, maybe use a neutral form). \\n\\n\"Agentic AI\" is a technical term. \"Agentic\" here likely refers to \"agent-based\" or \"autonomous\" AI. In Hindi, \"agentic AI\" might be translated as \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à\" since it\\'s a specific term and not commonly translated. Alternatively, maybe \"‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§à\" but \"agentic\" could be a specific term so keeping it in English with Hindi script might be better. \\n\\nPutting it all together: \\n\\n‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å. \\n\\nWait, let me check the structure again. \\n\\n\"My name is Rehaman\" becomes \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à\" which is more natural. \\n\\nThe part \"I want to learn agentic AI\" would then be \"‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". \\n\\nAlternatively, if the user is female, it would be \"‡§ö‡§æ‡§π‡§§‡•Ä ‡§π‡•Ç‡§Å\", but since the name Rehaman could be either gender, maybe using masculine is safer unless specified otherwise. \\n\\nAlso, \"agentic AI\" ‚Äì maybe some sources use \"‡§è‡§ú‡•á‡§Ç‡§ü ‡§Ü‡§à\" but since the user wrote \"agentic\", perhaps it\\'s better to transliterate \"agentic\" as \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï\" even if it\\'s not a standard Hindi word. \\n\\nYes, the translation should be:\\n\\n‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å‡•§ \\n\\nI think that\\'s correct. Let me double-check for any errors in grammar or structure. The sentence structure in Hindi is subject + verb, and the possessive \"my name\" is properly translated as \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ\". The verb \"to be\" is \"‡§π‡•à\" which matches the subject. \\n\\nYes, this should be accurate.\\n</think>\\n\\n‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡•á‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å‡•§' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 705, 'prompt_tokens': 53, 'total_tokens': 758, 'completion_time': 1.7342638940000001, 'prompt_time': 0.006047706, 'queue_time': 0.250072794, 'total_time': 1.7403116}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None} id='run--888ae049-6d57-4266-a67e-07317e2c0a16-0' usage_metadata={'input_tokens': 53, 'output_tokens': 705, 'total_tokens': 758}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f608aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user wants to translate \"hii how are you\" into German. Let me start by breaking down the sentence. \"Hii\" is a casual or informal way of saying \"hi\" or \"hello,\" maybe a bit more stretched for emphasis. In German, the equivalent would be \"Hi\" or \"Hallo.\" Since it\\'s already \"Hi\" in English, translating it to German would just be \"Hi\" as well, but maybe they want it more formal? Wait, the user specified to convert to German, so \"Hi\" is acceptable.\\n\\nNext, \"how are you?\" is the main part. The standard translation for \"how are you?\" in German is \"Wie geht\\'s?\" which is informal. But if they want a slightly more formal version, it would be \"Wie geht es Ihnen?\" when addressing someone with \"Sie,\" or \"Wie geht es dir?\" for informal \"du.\" The original \"hii\" seems informal, so probably using \"dir\" is better here. However, the user might just want the standard translation. Let me check for commonality. \"Wie geht\\'s?\" is more colloquial and matches the informal \"hii.\" \\n\\nPutting it all together: \"Hi, wie geht\\'s?\" That keeps the informal tone consistent. Alternatively, \"Hallo, wie geht es dir?\" could also work, but the user might prefer brevity. Also, \"hii\" is sometimes spelled with extra letters for effect, but in German, it\\'s still \"Hi.\" I should make sure there\\'s no typo here. \\n\\nWait, maybe the user wants the translation of the entire phrase as a single sentence. Let me confirm the structure. The original is \"hii how are you\" ‚Äì maybe they want it as one sentence without a comma? But in German, the comma is important. \"Hi wie geht\\'s?\" without a comma would be less natural. So including the comma is better. \\n\\nAlso, check for any regional variations. In some German-speaking regions, people might use different phrases, but \"Wie geht\\'s?\" is widely understood. \\n\\nAnother consideration: The user might have a typo in \"hii,\" but since they wrote it as \"hii,\" I should stick to translating that exactly. So \"Hi\" in German, then the rest. \\n\\nI think \"Hi, wie geht\\'s?\" is the best translation here. It\\'s informal, matches the original\\'s tone, and is commonly used.\\n</think>\\n\\nHallo, wie geht es dir?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain= prompt|model|parser\n",
    "response=chain.invoke({\n",
    "    \"language\":\"german\",\n",
    "    \"text\":\"hii how are you\"\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "746cbd15",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: <think>\nOkay, the user wants me to translate \"my name is rehaman, I want to learn agentic AI\" into Hindi. Let me break this down. First, the name \"rehaman\" ‚Äì since it's a name, I should keep it as is, maybe in Hindi script? Wait, but the user might prefer it in English. Hmm, the example they gave earlier used the name as is. So probably just transliterate the rest.\n\n\"My name is\" translates to \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à\" in Hindi. Then the name remains \"rehaman\". Next, \"I want to learn\" is \"‡§Æ‡•à‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" or \"‡§Æ‡•à‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•Ä ‡§π‡•Ç‡§Å\" depending on gender. Since the original doesn't specify, maybe use the masculine form as default. \n\nThen \"agentic AI\" ‚Äì \"agentic\" here likely refers to \"agentic AI systems\" or \"agentic artificial intelligence\". The term \"agentic\" might not have a direct translation. Maybe keep it as is in English or transliterate. Since technical terms are often kept in English, but to make it Hindi, perhaps \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\" would work. \n\nPutting it all together: \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à rehaman, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". Wait, should there be a comma? In Hindi, punctuation is similar. Also check the sentence structure. \n\nWait, \"want to learn\" is \"‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". So the full translation would be \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à rehaman, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". That seems correct. \n\nBut should \"AI\" be written in Hindi letters? Like \"‡§ê\" but usually AI is written as AI in Hindi texts. So the translation looks good. Make sure to return only the JSON with this translation. No markdown, just the JSON object. Let me double-check the structure and the terms. Yep, that should be it.\n</think>\n\n{\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à ‡§∞‡•á‡§π‡§Æ‡§æ‡§®, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:88\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\utils\\json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m chain = prompt | model | parser\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Step 6: Invoke the chain\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlanguage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhindi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy name is rehaman, I want to learn agentic AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sk Abdul Rehaman\\OneDrive\\Desktop\\Rehaman_resources\\codes\\AgenticAI\\venv\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:91\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     90\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: <think>\nOkay, the user wants me to translate \"my name is rehaman, I want to learn agentic AI\" into Hindi. Let me break this down. First, the name \"rehaman\" ‚Äì since it's a name, I should keep it as is, maybe in Hindi script? Wait, but the user might prefer it in English. Hmm, the example they gave earlier used the name as is. So probably just transliterate the rest.\n\n\"My name is\" translates to \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à\" in Hindi. Then the name remains \"rehaman\". Next, \"I want to learn\" is \"‡§Æ‡•à‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\" or \"‡§Æ‡•à‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•Ä ‡§π‡•Ç‡§Å\" depending on gender. Since the original doesn't specify, maybe use the masculine form as default. \n\nThen \"agentic AI\" ‚Äì \"agentic\" here likely refers to \"agentic AI systems\" or \"agentic artificial intelligence\". The term \"agentic\" might not have a direct translation. Maybe keep it as is in English or transliterate. Since technical terms are often kept in English, but to make it Hindi, perhaps \"‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI\" would work. \n\nPutting it all together: \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à rehaman, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". Wait, should there be a comma? In Hindi, punctuation is similar. Also check the sentence structure. \n\nWait, \"want to learn\" is \"‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". So the full translation would be \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à rehaman, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\". That seems correct. \n\nBut should \"AI\" be written in Hindi letters? Like \"‡§ê\" but usually AI is written as AI in Hindi texts. So the translation looks good. Make sure to return only the JSON with this translation. No markdown, just the JSON object. Let me double-check the structure and the terms. Yep, that should be it.\n</think>\n\n{\"translation\": \"‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§π‡•à ‡§∞‡•á‡§π‡§Æ‡§æ‡§®, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï AI ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å\"}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Step 1: Define the JSON parser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Step 2: Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an expert translator. Return ONLY this exact JSON format: {{\\\"translation\\\": \\\"...\\\"}}. No explanations, no markdown, no extra text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"Translate the following text into '{language}' language:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# Step 3: Inject format instructions from the parser\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# Step 4: Define the model\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "\n",
    "# Step 5: Create the chain\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Step 6: Invoke the chain\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a0874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3d8cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': '‡§Æ‡•á‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§∞‡§π‡§Æ‡§æ‡§® ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§è‡§ú‡•á‡§Ç‡§ü‡§ø‡§ï ‡§è‡§Ü‡§à ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Å'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an expert translator. Return ONLY this exact JSON format: {{\\\"translation\\\": \\\"...\\\"}}. No explanations, no markdown, no extra text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"Translate the following text into '{language}' language:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "model = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"language\": \"hindi\",\n",
    "    \"text\": \"my name is rehaman, I want to learn agentic AI\"\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c04e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
